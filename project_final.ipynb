{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1,\"src\")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import dlc_practical_prologue as dl\n",
    "from opt import (\n",
    "    Net2,\n",
    "    train_model,\n",
    "    get_accuracy,\n",
    "    Kfold_CV,\n",
    "    Naive,\n",
    "    WeightAux,\n",
    "    get_double_accuracy,\n",
    "    train_double_model,\n",
    "    Kfold_CVdouble,\n",
    ")\n",
    "from misc_funcs import RANDOM_SEED, EXPLORE_K, BIG_K, NB_EPOCHS, sep\n",
    "N_SAMPLES = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.L1Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeightAux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project respects the following structure:\n",
    "Simple Network:\n",
    "```\n",
    "    .\n",
    "    ├── Simple Network               \n",
    "    │   ├── Net2    \n",
    "    │   ├── get_accuracy()         \n",
    "    │   ├── train_model()  \n",
    "    │   ├── Kfold_CV()\n",
    "    ├── Double Network\n",
    "    │   ├── Naive\n",
    "    │   ├── WeightAux\n",
    "    │   ├── accuracy_double_model()   \n",
    "    │   ├── train_double_model()   \n",
    "    │   ├── Kfold_CVdouble()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, test_input, test_target = dl.load_data(flatten=False)\n",
    "train_input = torch.functional.F.avg_pool2d(train_input, kernel_size=2)\n",
    "test_input = torch.functional.F.avg_pool2d(test_input, kernel_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "We start by implementing a simple handmade-optimized CNN that performs decently on the MNIST dataset (nets.Net2): we will use it as the reference throuhghout the project for comparison purposes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:96.00 %\n",
      "--------------------\n",
      "Train accuracy: 1.00\n",
      "Test accuracy: 0.95\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net2()\n",
    "architecture = Net2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam\n",
    "lr = 1e-3\n",
    "train_model(train_input,train_target,model,criterion=criterion,optimizer=optimizer,lr=lr,verbose=True)\n",
    "print(sep)\n",
    "_ = get_accuracy(model, train_input, train_target, \"Train\")\n",
    "_ = get_accuracy(model, test_input, test_target, \"Test\")\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "As we can see, the model overfits on the train set and performs well enough for the comparison purpose, although some parameter tuning could probably get this accuracy higher.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "In order to get more robust estimates, a KFold Cross validation method was implemented as well\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Accuracies for 10-fold:[0.9399999976158142, 0.949999988079071, 0.949999988079071, 0.9399999976158142, 0.9200000166893005, 0.949999988079071, 0.9599999785423279, 0.9599999785423279, 0.9399999976158142, 0.9800000190734863]\n",
      "Accuracy:0.95 +- 0.02\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "accuracies = Kfold_CV(train_input, train_target, architecture, criterion, optimizer, lr, K=BIG_K, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with double Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "We now implement 4 different model architectures in order to assess the performance improvement that can be achieved through weight sharing or auxiliary loss. \n",
    "    \n",
    "* Naive model, where we just train 2 networks in parallel and trivially compare the output\n",
    "* Weight Sharing (Model 1)\n",
    "* Auxiliary loss (Model 2)\n",
    "* No extension (Model 3)\n",
    "* Auxiliary loss + Weight sharing (Model 4)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = dl.load_data(flatten=False)\n",
    "train2_input, train2_target, train2_classes = dl.mnist_to_pairs(N_SAMPLES, a, b)\n",
    "test2_input, test2_target, test2_classes = dl.mnist_to_pairs(N_SAMPLES, c, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "We first get a first feeling by optimizing the double network by hand....\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Firs the naive model:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters definition\n",
    "crit_comp = nn.CrossEntropyLoss\n",
    "crit_class = nn.CrossEntropyLoss\n",
    "optimizer = optim.Adam\n",
    "lr = 1e-3\n",
    "naive_baseline = Naive()\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:96.00 %\n",
      "--------------------Train--------------------\n",
      "Accuracy 1st Network:    1.00   \n",
      "Accuracy 2nd Network:    1.00   \n",
      "Accuracy comparison:     1.00    \n",
      "--------------------Test--------------------\n",
      "Accuracy 1st Network:    0.92   \n",
      "Accuracy 2nd Network:    0.91   \n",
      "Accuracy comparison:     0.94    \n"
     ]
    }
   ],
   "source": [
    "train_double_model(train2_input,train2_target,train2_classes,naive_baseline,\n",
    "                   crit_comp,crit_class,optimizer,lr,nb_epochs=NB_EPOCHS,verbose=True,prog_bar=True)\n",
    "print(sep + \"Train\" + sep)\n",
    "_ = get_double_accuracy(naive_baseline, train2_input, train2_target, train2_classes, verbose=True)\n",
    "print(sep + \"Test\" + sep)\n",
    "_ = get_double_accuracy(naive_baseline, test2_input, test2_target, test2_classes, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "More robust metric thanks to KFold cross validation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation Accuracies for 10-fold:--------------------\n",
      "Accuracy 1st network: 0.92 +- 0.04\n",
      "Accuracy 2nd network: 0.95 +- 0.03\n",
      "Accuracy comparison:  0.96 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "_ = Kfold_CVdouble(train2_input,train2_target,train2_classes,\n",
    "                   Naive(),crit_comp,crit_class,optimizer,lr,K=BIG_K,verbose=True,prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "And we proceed similarly for the weight sharing\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters definition\n",
    "crit_comp = nn.CrossEntropyLoss\n",
    "crit_class = nn.CrossEntropyLoss\n",
    "optimizer = optim.Adam\n",
    "lr = 1e-3\n",
    "lambda_ = 0.75\n",
    "net2 = WeightAux(True, True)\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Train accuracy:--------------------\n",
      "Accuracy 1st Network:    1.00   \n",
      "Accuracy 2nd Network:    1.00   \n",
      "Accuracy comparison:     1.00    \n",
      "--------------------Test accuracy:--------------------\n",
      "Accuracy 1st Network:    0.95   \n",
      "Accuracy 2nd Network:    0.93   \n",
      "Accuracy comparison:     0.86    \n"
     ]
    }
   ],
   "source": [
    "train_double_model(train2_input,train2_target,train2_classes,\n",
    "                   net2,crit_comp,crit_class,optimizer,lr,lambda_,nb_epochs=NB_EPOCHS,verbose=True,prog_bar=False)\n",
    "print(sep + \"Train accuracy:\" + sep)\n",
    "_ = get_double_accuracy(\n",
    "    net2, train2_input, train2_target, train2_classes, verbose=True\n",
    ")\n",
    "print(sep + \"Test accuracy:\" + sep)\n",
    "_ = get_double_accuracy(net2, test2_input, test2_target, test2_classes, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation Accuracies for 2-fold:--------------------\n",
      "Accuracy 1st network: 0.92 +- 0.01\n",
      "Accuracy 2nd network: 0.92 +- 0.02\n",
      "Accuracy comparison:  0.82 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "acc_list = Kfold_CVdouble(train2_input,train2_target,train2_classes,WeightAux(True, True),crit_comp,\n",
    "                          crit_class,optimizer,lr,lambda_,K=2,verbose=True,prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "In order to improve the models mentionned above 2 types of hyperparameters optimization method were implemented:\n",
    "    \n",
    "* Grid Search\n",
    "* Genetic Algorithm\n",
    "    \n",
    "Both of these methods rely on the following param class which allow intuitive subsequent optimization.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local\n",
    "from hyperopt import Param, HyperGrid, GetNTop, GetMax\n",
    "from gridsearch import GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Architecture\n",
    "Archis = [\n",
    "    WeightAux(True, True),\n",
    "    WeightAux(True, False),\n",
    "    WeightAux(False, True),\n",
    "    WeightAux(False, False),\n",
    "]\n",
    "# 2 Comparison Loss Function\n",
    "CompLoss = [nn.CrossEntropyLoss, nn.NLLLoss, nn.MSELoss,nn.L1Loss]\n",
    "# 3 Class Loss Functions\n",
    "ClassLoss = [nn.CrossEntropyLoss, nn.NLLLoss, nn.MSELoss,nn.L1Loss]\n",
    "# 4 Optimizers\n",
    "Optimizers = [optim.SGD, optim.Adam, optim.Adagrad, optim.AdamW]\n",
    "# 5 Learning Rates\n",
    "LRs = [1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "# 6 Ratios\n",
    "Lambdas = [0.2, 0.4, 0.7, 0.9]\n",
    "HYPER_PARAMS = [Archis, CompLoss,ClassLoss, Optimizers, LRs, Lambdas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the existing HyperGrid\n"
     ]
    }
   ],
   "source": [
    "path= Path(\"./results/HYPERPARAM.pkl\")\n",
    "if path.exists():\n",
    "    print(\"loading the existing HyperGrid\")\n",
    "    HG = torch.load(path)\n",
    "else: \n",
    "    HG = HyperGrid(*HYPER_PARAMS, \"./results/HYPERPARAM.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.0 hours, 3.0 minutes\n"
     ]
    }
   ],
   "source": [
    "HG = HyperGrid(*HYPER_PARAMS, \"./results/HYPERPARAM.pkl\")\n",
    "\n",
    "HG.estimate_time(train2_input, train2_target, train2_classes, K=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search progression: 99.98 %\n",
      "Grid Search done! Hyperparam saved.\n",
      "CPU times: user 12h 21min 56s, sys: 13min 38s, total: 12h 35min 34s\n",
      "Wall time: 6h 36min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GridSearch(HG,train2_input,train2_target,train2_classes,K=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Model Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER_PARAMS_NAIVE = [[Naive()], [nn.CrossEntropyLoss],ClassLoss, Optimizers, LRs, [0]]\n",
    "HG_naive = HyperGrid(*HYPER_PARAMS_NAIVE, \"./results/HYPERPARAM_naive.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the existing HyperGrid\n"
     ]
    }
   ],
   "source": [
    "path= Path(\"./results/HYPERPARAM_naive.pkl\")\n",
    "if path.exists():\n",
    "    print(\"loading the existing HyperGrid\")\n",
    "    HG_naive = torch.load(path)\n",
    "else: \n",
    "    HG_naive = HyperGrid(*HYPER_PARAMS, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search progression: 98.75 %\n",
      "Grid Search done! Hyperparam saved.\n"
     ]
    }
   ],
   "source": [
    "GridSearch(HG_naive,train2_input,train2_target,train2_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOP = 3\n",
    "naive_res  = GetNTop(HG_naive.lin_view(),N_TOP)\n",
    "model1_res = GetNTop([i for i in HG.lin_view() if \"_Weightshare_\" in str(i)],N_TOP)\n",
    "model2_res = GetNTop([i for i in HG.lin_view() if \"_Auxloss_\" in str(i)],N_TOP)\n",
    "model3_res = GetNTop([i for i in HG.lin_view() if \"_classic_\" in str(i)],N_TOP)\n",
    "model4_res = GetNTop([i for i in HG.lin_view() if \"_WeightshareAuxloss_\" in str(i)],N_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NaiveArch_CrossEntropyLoss_CrossEntropyLoss_AdamW_0.01_0_#ind#_-1.00_#score#_0.95,\n",
       " NaiveArch_CrossEntropyLoss_CrossEntropyLoss_Adam_0.01_0_#ind#_-1.00_#score#_0.96,\n",
       " NaiveArch_CrossEntropyLoss_CrossEntropyLoss_Adagrad_0.01_0_#ind#_-1.00_#score#_0.94]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation Accuracies for 10-fold:--------------------\n",
      "Accuracy 1st network: 0.93 +- 0.04\n",
      "Accuracy 2nd network: 0.94 +- 0.03\n",
      "Accuracy comparison:  0.95 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "_ = naive_res[0].KFold(train2_input,train2_target,train2_classes,K=BIG_K,verbose=True,prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Arch_Weightshare_CrossEntropyLoss_L1Loss_Adagrad_0.001_0.9_#ind#_-1.00_#score#_0.82,\n",
       " Arch_Weightshare_CrossEntropyLoss_L1Loss_Adagrad_0.001_0.7_#ind#_-1.00_#score#_0.81,\n",
       " Arch_Weightshare_CrossEntropyLoss_L1Loss_Adagrad_0.001_0.4_#ind#_-1.00_#score#_0.81]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation Accuracies for 10-fold:--------------------\n",
      "Accuracy 1st network: 0.13 +- 0.06\n",
      "Accuracy 2nd network: 0.11 +- 0.04\n",
      "Accuracy comparison:  0.82 +- 0.05\n"
     ]
    }
   ],
   "source": [
    "_ = model1_res[0].KFold(train2_input,train2_target,train2_classes,K=BIG_K,verbose=True,prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Arch_Auxloss_L1Loss_CrossEntropyLoss_AdamW_0.01_0.2_#ind#_-1.00_#score#_0.87,\n",
       " Arch_Auxloss_MSELoss_CrossEntropyLoss_AdamW_0.01_0.2_#ind#_-1.00_#score#_0.86,\n",
       " Arch_Auxloss_MSELoss_CrossEntropyLoss_Adagrad_0.01_0.2_#ind#_-1.00_#score#_0.86]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation Accuracies for 10-fold:--------------------\n",
      "Accuracy 1st network: 0.93 +- 0.06\n",
      "Accuracy 2nd network: 0.94 +- 0.04\n",
      "Accuracy comparison:  0.90 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "_ = model2_res[0].KFold(train2_input,train2_target,train2_classes,K=BIG_K,verbose=True,prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Arch_classic_MSELoss_L1Loss_Adagrad_0.01_0.9_#ind#_-1.00_#score#_0.82,\n",
       " Arch_classic_MSELoss_L1Loss_Adagrad_0.01_0.7_#ind#_-1.00_#score#_0.82,\n",
       " Arch_classic_MSELoss_L1Loss_Adagrad_0.01_0.4_#ind#_-1.00_#score#_0.82]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation Accuracies for 10-fold:--------------------\n",
      "Accuracy 1st network: 0.11 +- 0.04\n",
      "Accuracy 2nd network: 0.14 +- 0.09\n",
      "Accuracy comparison:  0.79 +- 0.05\n"
     ]
    }
   ],
   "source": [
    "_ = model3_res[0].KFold(train2_input,train2_target,train2_classes,K=BIG_K,verbose=True,prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Arch_WeightshareAuxloss_L1Loss_CrossEntropyLoss_Adam_0.01_0.2_#ind#_-1.00_#score#_0.87,\n",
       " Arch_WeightshareAuxloss_MSELoss_CrossEntropyLoss_Adagrad_0.01_0.2_#ind#_-1.00_#score#_0.87,\n",
       " Arch_WeightshareAuxloss_MSELoss_CrossEntropyLoss_Adam_0.01_0.2_#ind#_-1.00_#score#_0.87]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation Accuracies for 10-fold:--------------------\n",
      "Accuracy 1st network: 0.95 +- 0.04\n",
      "Accuracy 2nd network: 0.95 +- 0.03\n",
      "Accuracy comparison:  0.91 +- 0.04\n"
     ]
    }
   ],
   "source": [
    "_  = model4_res[0].KFold(train2_input,train2_target,train2_classes,K=BIG_K,verbose=True,prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genetic import (\n",
    "    generate_population,\n",
    "    compute_individuality,\n",
    "    compute_fitness,\n",
    "    selection,\n",
    "    breed,\n",
    "    plot_population,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Param.set_hyper_params(HYPER_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* START<br>\n",
    "    - Generate the initial population<br>\n",
    "    - Compute fitness<br>\n",
    "* REPEAT<br>\n",
    "    - Selection<br>\n",
    "    - Crossover<br>\n",
    "    - Mutation<br>\n",
    "    - Compute fitness<br>\n",
    "* UNTIL population has converged<br>\n",
    "* STOP<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption: complex : hill climbing algorithm might get stuck in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Progression: 96.66666666666667 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37min 42s, sys: 41.7 s, total: 38min 24s\n",
      "Wall time: 19min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "####################################\n",
    "# size of the population\n",
    "N_POP = 10\n",
    "# number of iteration of selection\n",
    "N_ITER = 30\n",
    "# selection ratio\n",
    "SELEC_RATIO = 0.6\n",
    "# chance of mutation\n",
    "CHANCE = 0.1\n",
    "# number of fold for evaluation\n",
    "K = 3\n",
    "####################################\n",
    "\n",
    "# we keep a param to receive\n",
    "best_indiv = Param()\n",
    "# initial population\n",
    "population = generate_population(N_POP)\n",
    "compute_fitness(\n",
    "    train2_input, train2_target, train2_classes, population, K=K, verbose=True\n",
    ")\n",
    "compute_individuality(population)\n",
    "for i in range(N_ITER):\n",
    "    clear_output(wait=False)\n",
    "    print(\"Population Progression: {} %\".format(i / N_ITER * 100))\n",
    "    plot_population(population)\n",
    "    plt.pause(0.05)\n",
    "    population = selection(population, selec_ratio=SELEC_RATIO)\n",
    "    if population[0].score_mean > best_indiv.score_mean:\n",
    "        best_indiv = population[0]\n",
    "    population = breed(population, n_pop=N_POP, chance=CHANCE)\n",
    "    compute_fitness(train2_input, train2_target, train2_classes, population, K=K)\n",
    "    compute_individuality(population)\n",
    "    torch.save(population,\"./results/GEN_ALG.pickle\", pickle_module=pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Once again, we compute the score on a bigger K-fold for consistent results\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = torch.load(\"./results/GEN_ALG.pickle\", pickle_module=pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_res = GetNTop(population,N_TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Arch_WeightshareAuxloss_L1Loss_CrossEntropyLoss_AdamW_0.001_0.7_#ind#_0.26_#score#_0.85,\n",
       " Arch_WeightshareAuxloss_CrossEntropyLoss_CrossEntropyLoss_Adam_0.001_0.7_#ind#_0.07_#score#_0.83,\n",
       " Arch_Weightshare_CrossEntropyLoss_CrossEntropyLoss_Adam_0.001_0.7_#ind#_0.00_#score#_0.79]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation Accuracies for 10-fold:--------------------\n",
      "Accuracy 1st network: 0.93 +- 0.04\n",
      "Accuracy 2nd network: 0.94 +- 0.04\n",
      "Accuracy comparison:  0.87 +- 0.04\n"
     ]
    }
   ],
   "source": [
    "_ = gen_res[0].KFold(train2_input,train2_target,train2_classes,K=BIG_K,verbose=True,prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
