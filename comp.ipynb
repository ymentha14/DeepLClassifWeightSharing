{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import pickle\n",
    "import copy\n",
    "import math\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import dlc_practical_prologue as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"#\" * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = dl.load_data(flatten=False)\n",
    "train_input = torch.functional.F.avg_pool2d(train_input, kernel_size = 2)\n",
    "test_input = torch.functional.F.avg_pool2d(test_input, kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self,n_hidden = 100,chan = 1):\n",
    "        super(Net2,self).__init__()\n",
    "        self.hidden = n_hidden\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(chan,32,kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            ,nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256,n_hidden),\n",
    "           # nn.Dropout(0.5),\n",
    "            nn.Linear(n_hidden,10)\n",
    "            #nn.Softmax2d()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.classifier(x.view(x.size(0),-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,inputs,targets):\n",
    "    assert(inputs.size(0) == targets.size(0))\n",
    "    tot_loss = 0\n",
    "    nb_correct = 0\n",
    "    batch_size = 20\n",
    "    for train,target in zip(inputs.split(batch_size),\n",
    "                           targets.split(batch_size)):\n",
    "        pred = model(train)\n",
    "        pred = torch.argmax(pred,axis = 1)\n",
    "        nb_correct += (pred == target).int().sum().item()\n",
    "    accuracy = nb_correct /inputs.size(0)\n",
    "    print(\"accuracy: %.2f\" % (accuracy) )\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_input,train_target,nb_epochs=25):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "    batch_size = 100\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for e in range(nb_epochs):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Progression:{:.2f}\".format(e/nb_epochs*100))\n",
    "        for inputs,targets in zip(train_input.split(batch_size),\n",
    "                            train_target.split(batch_size)):\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output,targets)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:48.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-76524bee2e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ffbbadc2a9f1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_input, train_target, nb_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m         for inputs,targets in zip(train_input.split(batch_size),\n\u001b[1;32m      9\u001b[0m                             train_target.split(batch_size)):\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-dee85d1793f1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net2()\n",
    "train_model(model,train_input,train_target)\n",
    "get_accuracy(model,train_input,train_target)\n",
    "get_accuracy(model,test_input,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kfold_CV(classtype,inputs,targets,K=4):\n",
    "    assert(K>=2)\n",
    "    N = inputs.size(0)\n",
    "    indxes = torch.randperm(N)\\\n",
    "                  .split(int(N/K))\n",
    "    accs = torch.empty(K)\n",
    "    for k in range(K):\n",
    "        model = classtype()\n",
    "        \n",
    "        test_indx = indxes[k]\n",
    "        train_indx = torch.cat((indxes[:k]+indxes[k+1:]),0)\n",
    "        \n",
    "        train_inp,train_targ = inputs[train_indx],targets[train_indx]\n",
    "        test_inp,test_targ = inputs[test_indx],targets[test_indx]\n",
    "        train_model(model,train_inp,train_targ)\n",
    "        acc = get_accuracy(model,test_inp,test_targ)\n",
    "        accs[k] = acc\n",
    "    print(\"Accuracies for {}-fold:{}\".format(K,accs.tolist()))\n",
    "    print(\"Mean acc:{}\".format(accs.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:48.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5b1501bb22ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mKfold_CV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-2770f8effa27>\u001b[0m in \u001b[0;36mKfold_CV\u001b[0;34m(classtype, inputs, targets, K)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_targ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtest_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_targ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_targ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_targ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0maccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ffbbadc2a9f1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_input, train_target, nb_epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;34mr\"\"\"Sets gradients of all model parameters to zero.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self, recurse)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         \"\"\"\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_parameters\u001b[0;34m(self, prefix, recurse)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             prefix=prefix, recurse=recurse)\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_named_members\u001b[0;34m(self, get_members_fn, prefix, recurse)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;34mr\"\"\"Helper method for yielding various names + members of modules.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m         \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Kfold_CV(Net2,train_input,train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with double Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Naive,self).__init__()\n",
    "        self.net0 = Net2()\n",
    "        self.net1 = Net2()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x0 = self.net0(x[:,0].unsqueeze(1))\n",
    "        x1 = self.net1(x[:,1].unsqueeze(1))\n",
    "        comp = (x0.max(1)[1] <= x1.max(1)[1]).int()\n",
    "        ret = torch.FloatTensor(comp.size(0),2).zero_()\n",
    "        ret.scatter_(1, comp.long().unsqueeze(1), 1)\n",
    "        return x0,x1,ret\n",
    "    def __str__(self):\n",
    "        stro = \"Arch\"\n",
    "        if self.weightshare:\n",
    "            stro += \"W\"\n",
    "        if self.auxloss:\n",
    "            stro += \"A\"\n",
    "        return stro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightAux(nn.Module):\n",
    "    def __init__(self,weightshare=True,auxloss=True):\n",
    "        super(WeightAux,self).__init__()\n",
    "        self.weightshare = weightshare\n",
    "        self.auxloss = auxloss\n",
    "        self.net0 = Net2()\n",
    "        self.net1 = Net2()\n",
    "        self.linblock = nn.Sequential(nn.Linear(20,40),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(40,80),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(80,2))\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x0 = self.net0(x[:,0].unsqueeze(1))\n",
    "        x1 = self.net0(x[:,1].unsqueeze(1)) if self.weightshare else self.net0(x[:,1].unsqueeze(1))\n",
    "        comp = torch.cat((x0,x1),dim=1)\n",
    "        comp = self.linblock(comp)\n",
    "        return x0,x1,comp\n",
    "    def __str__(self):\n",
    "        stro = \"Arch\"\n",
    "        if self.weightshare:\n",
    "            stro += \"W\"\n",
    "        if self.auxloss:\n",
    "            stro += \"A\"\n",
    "        return stro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_double_model(model,train_input,train_target,train_classes,verbose=False):\n",
    "    assert(train_input.size(0) == train_target.size(0))\n",
    "    N = train_input.size(0)\n",
    "    tot_loss = 0\n",
    "    nb_correct = 0\n",
    "    batch_size = 20\n",
    "    \n",
    "    #given a prediction powre and the target, output the number of correctly classified samples\n",
    "    add_res = lambda pred,target:(torch.argmax(pred,axis = 1) == target).int().sum().item()\n",
    "    \n",
    "    score0 = 0\n",
    "    score1 = 0\n",
    "    scorecomp = 0\n",
    "    \n",
    "    for inputs,comp_targs,classes in zip(train_input.split(batch_size),\n",
    "                                           train_target.split(batch_size),\n",
    "                                        train_classes.split(batch_size)):\n",
    "        targ0 = classes[:,0]\n",
    "        targ1 = classes[:,1]\n",
    "        x0,x1,comp = model(inputs)\n",
    "        \n",
    "        score0 += add_res(x0,targ0)\n",
    "        score1 += add_res(x1,targ1)\n",
    "        scorecomp += add_res(comp,comp_targs)\n",
    "        \n",
    "    acc0 = score0 / N\n",
    "    acc1 = score1 / N\n",
    "    acc_comp = scorecomp / N\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Accuracy 1st Network: {:^10.2f}\".format(acc0) )\n",
    "        print(\"Accuracy 2nd Network: {:^10.2f}\".format(acc1))\n",
    "        print(\"Accuracy comparison: {:^12.2f}\".format(acc_comp))\n",
    "\n",
    "    return acc0,acc1,acc_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_double_model(train_input,train_target,train_classes,\\\n",
    "                       model,crit_comp,optimizer,lr,lambd_,nb_epochs=5,verbose=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: the model to train (3 arch)\n",
    "        crit_comp: the criterion for comparison (2 sorts)\n",
    "        optimizer: the chosen optimizer (3 types)\n",
    "        lr: learning rate (4 types)\n",
    "        ratio loss: the amount of each loss (3 values)\n",
    "        lambd_: ratio lambd_ * comp_loss + (1-lambd_) * class_loss\n",
    "    \"\"\"\n",
    "    crit_comp = crit_comp()\n",
    "    optimizer = optimizer(model.parameters(), lr = lr)\n",
    "\n",
    "    batch_size = 100\n",
    "    crit_class = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        if verbose:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Progression:{:.2f}\".format(e/nb_epochs*100))\n",
    "        for inputs,comp_targs,classes in zip(train_input.split(batch_size),\n",
    "                                           train_target.split(batch_size),\n",
    "                                           train_classes.split(batch_size)):\n",
    "            y_onehot = torch.FloatTensor(inputs.size(0),2).zero_()\n",
    "            targ0 = classes[:,0]\n",
    "            targ1 = classes[:,1]\n",
    "            x0,x1,comp = model(inputs)\n",
    "            loss_class = crit_class(x0,targ0) + crit_class(x1,targ1)\n",
    "            if (isinstance(crit_comp,(nn.CrossEntropyLoss,nn.NLLLoss))):\n",
    "                loss_comp = crit_comp(comp,comp_targs)\n",
    "            else:\n",
    "                y_onehot.zero_()\n",
    "                y_onehot.scatter_(1, comp_targs.unsqueeze(1), 1)\n",
    "                loss_comp = crit_comp(comp,y_onehot)\n",
    "            if (isinstance(model,Naive)):\n",
    "                totloss = loss_class\n",
    "            elif model.auxloss:\n",
    "                totloss = lambd_ * loss_comp + (1- lambd_) *loss_class\n",
    "            else:\n",
    "                totloss = loss_comp\n",
    "            model.zero_grad()\n",
    "            totloss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kfold_CVdouble(inputs,targets,classes,\\\n",
    "                   model_template,crit_comp,optimizer,lr,lambd_,K=4,nb_epochs=5,verbose=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model_template: the type of architecture for classif (3 arch)\n",
    "        crit_comp: the criterion for comparison (2 sorts)\n",
    "        optimizer: the chosen optimizer (3 types)\n",
    "        lr: learning rate (4 types)\n",
    "        ratio loss: the amount of each loss (3 values)\n",
    "        lambd_: ratio lambd_ * comp_loss + (1-lambd_) * class_loss\n",
    "    \"\"\"\n",
    "    assert(K>=2)\n",
    "    N = inputs.size(0)\n",
    "    indxes = torch.randperm(N)\\\n",
    "                  .split(int(N/K))\n",
    "    accs = torch.empty(K,3)\n",
    "    for k in range(K):\n",
    "        model = copy.deepcopy(model_template)\n",
    "        \n",
    "        test_indx = indxes[k]\n",
    "        train_indx = torch.cat((indxes[:k]+indxes[k+1:]),0)\n",
    "        \n",
    "        train_inp = inputs[train_indx]\n",
    "        train_targ = targets[train_indx]\n",
    "        train_classes = classes[train_indx]\n",
    "        \n",
    "        test_inp  = inputs[test_indx]\n",
    "        test_targ = targets[test_indx]\n",
    "        test_classes = classes[test_indx]\n",
    "        \n",
    "        train_double_model(train_inp,train_targ,train_classes,\\\n",
    "                          model,crit_comp,optimizer,lr,lambd_,nb_epochs=nb_epochs,verbose=verbose)\n",
    "        res = accuracy_double_model(model,test_inp,test_targ,test_classes)\n",
    "        #0th column: 1st group acc 1th column 2nd group acc 3rd column comp accuracy\n",
    "        accs[k] = torch.Tensor(res)\n",
    "    if verbose:\n",
    "        print(sep + \"Accuracies for {}-fold:\".format(K) + sep)\n",
    "        print(\"1st group acc:{:^14.2f}\".format(accs[:,0].mean().item()))\n",
    "        print(\"2nd group acc:{:^14.2f}\".format(accs[:,1].mean().item()))\n",
    "        print(\"Comparison acc:{:^12.2f}\".format(accs[:,2].mean().item()))\n",
    "    return accs[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 500\n",
    "a, b, c, d = dl.load_data(flatten=False)\n",
    "train2_input, train2_target, train2_classes = dl.mnist_to_pairs(N_SAMPLES,a,b)\n",
    "test2_input, test2_target, test2_classes = dl.mnist_to_pairs(N_SAMPLES,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################Train accuracy:####################\n",
      "Accuracy 1st Network:    1.00   \n",
      "Accuracy 2nd Network:    1.00   \n",
      "Accuracy comparison:     1.00    \n",
      "####################Test accuracy:####################\n",
      "Accuracy 1st Network:    0.94   \n",
      "Accuracy 2nd Network:    0.93   \n",
      "Accuracy comparison:     0.90    \n"
     ]
    }
   ],
   "source": [
    "net2 = WeightAux(True,True)\n",
    "train_double_model(train2_input,train2_target,train2_classes,\\\n",
    "                   net2,nn.CrossEntropyLoss,optim.SGD,1e-0,0.75,nb_epochs=25)\n",
    "print(sep + \"Train accuracy:\" + sep)\n",
    "accuracy_double_model(net2,train2_input,train2_target,train2_classes,verbose=True)\n",
    "print(sep+ \"Test accuracy:\" + sep)\n",
    "_ = accuracy_double_model(net2,test2_input,test2_target,test2_classes,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:80.00\n",
      "####################Accuracies for 5-fold:####################\n",
      "1st group acc:     0.91     \n",
      "2nd group acc:     0.91     \n",
      "Comparison acc:    0.83    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8000, 0.8600, 0.8400, 0.8400, 0.8300])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kfold_CVdouble(train2_input,train2_target,train2_classes,\\\n",
    "               WeightAux(True,True),nn.CrossEntropyLoss,optim.SGD,1e-0,0.75,K=5,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Architecture\n",
    "Archis = [WeightAux(True,True),WeightAux(True,False),WeightAux(False,True),WeightAux(False,False)]\n",
    "#2 Comparison Loss Function\n",
    "CompLoss = [nn.CrossEntropyLoss,nn.NLLLoss,nn.MSELoss]\n",
    "#3 Optimizers\n",
    "Optimizers = [optim.SGD,optim.Adam,optim.Adagrad,optim.AdamW]\n",
    "#4 Learning Rates\n",
    "LRs = [1e-4,1e-3,1e-2,1e-1,1]\n",
    "#5 Ratios\n",
    "Lambdas = [0.2,0.4,0.7,0.9]\n",
    "HYPER_PARAMS = [Archis,CompLoss,Optimizers,LRs,Lambdas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param():\n",
    "    hyper_params = HYPER_PARAMS\n",
    "    rando = lambda lista: lista[torch.randint(len(lista),(1,)).item()]\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(classi):\n",
    "        return str(classi).split('.')[-1].split(\"'\")[0]\n",
    "\n",
    "    def __init__(self,arch=None,loss=None,optimizer=None,lr=None,lambd_=None):\n",
    "        if None in [arch,loss,optimizer,lr,lambd_]:\n",
    "            self.params = self.generate_rand_params()\n",
    "        else:\n",
    "            self.params = {\"arch\":arch,\n",
    "                           \"loss\":loss,\n",
    "                           \"optim\":optimizer,\n",
    "                           \"lr\":lr,\n",
    "                           \"lambda\":lambd_}\n",
    "        self.scores = []\n",
    "        self.score_mean = -1\n",
    "        self.individuality = -1\n",
    "    def get_params(self):\n",
    "        return list(self.params.values())\n",
    "    \n",
    "    def generate_rand_params(self):\n",
    "        rand_values = [Param.rando(param) for param in Param.hyper_params]\n",
    "        names = [\"arch\",\"loss\",\"optim\",\"lr\",\"lambda\"]\n",
    "        return {name:val for name,val in zip(names,rand_values)}\n",
    "    \n",
    "    def mutate(self):\n",
    "        param_indx = torch.randint(len(Param.hyper_params),(1,)).item()\n",
    "        values = Param.hyper_params[param_indx]\n",
    "        value_indx = torch.randint(len(values),(1,)).item()\n",
    "        #new value the param needs to take\n",
    "        value = values[value_indx]\n",
    "        key = list(self.params.keys())[param_indx]\n",
    "        #reassign to the random value\n",
    "        self.params[key] = value\n",
    "    \n",
    "    def KFold(self,K=5,verbose=False):\n",
    "        arch,loss,opt,lr,lambd_ = self.get_params()\n",
    "        scores = Kfold_CVdouble(train2_input,train2_target,train2_classes,\\\n",
    "                arch,loss,opt,lr,lambd_,K=K,verbose=verbose)\n",
    "        self.set_scores(scores)\n",
    "        return scores\n",
    "        \n",
    "    def set_scores(self,scores):\n",
    "        self.scores = scores.tolist()\n",
    "        self.score_mean = scores.mean().item()\n",
    "        self.score_std = scores.std().item()\n",
    "                \n",
    "         \n",
    "    def __str__(self):\n",
    "        returned = \"{}_{}_{}_{}_{}_#ind#_{:.2f}_#score#_{:.2f}\".format(Param.parse(self.params[\"arch\"]),\n",
    "                                               Param.parse(self.params[\"loss\"]),\n",
    "                                               Param.parse(self.params[\"optim\"]),\n",
    "                                               self.params[\"lr\"],\n",
    "                                               self.params[\"lambda\"],\n",
    "                                               self.individuality,\n",
    "                                               self.score_mean)\n",
    "        return returned\n",
    "    def __repr__(self):\n",
    "        return str(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER_GRID = torch.empty(len(Archis),len(CompLoss),len(Optimizers),len(LRs),len(Lambdas)).tolist()\n",
    "for a,archi in enumerate(Archis):\n",
    "    for b,loss in enumerate(CompLoss):\n",
    "        for c,optim_ in enumerate(Optimizers):\n",
    "            for d,lr in enumerate(LRs):\n",
    "                for e,lambd_ in enumerate(Lambdas):\n",
    "                    HYPER_GRID[a][b][c][d][e] = Param(archi,loss,optim_,lr,lambd_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_view(HYPER_GRID):\n",
    "    linHGRID = [e for a in HYPER_GRID for b in a for c in b for d in c for e in d]\n",
    "    return linHGRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch(linGRID):\n",
    "    for i,param in enumerate(linGRID):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Grid Search progression: {} %\".format(i/len(linGRID)*100))\n",
    "        param.KFold()\n",
    "    with open('./results/HYPERPARAM.pkl', 'wb') as f:\n",
    "        pickle.dump(HYPER_GRID,f)\n",
    "    print(\"Grid Search done! Hyperparam saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search progression: 0.0 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d7cfbb3e4b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlinGRID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlin_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHYPER_GRID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mGridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinGRID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-39f9a44df7d2>\u001b[0m in \u001b[0;36mGridSearch\u001b[0;34m(linGRID)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Grid Search progression: {} %\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinGRID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./results/HYPERPARAM.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHYPER_GRID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-77831331e448>\u001b[0m in \u001b[0;36mKFold\u001b[0;34m(self, K, verbose)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambd_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         scores = Kfold_CVdouble(train2_input,train2_target,train2_classes,\\\n\u001b[0;32m---> 42\u001b[0;31m                 arch,loss,opt,lr,lambd_,K=K,verbose=verbose)\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-b5a7ad1117e4>\u001b[0m in \u001b[0;36mKfold_CVdouble\u001b[0;34m(inputs, targets, classes, model_template, crit_comp, optimizer, lr, lambd_, K, nb_epochs, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         train_double_model(train_inp,train_targ,train_classes,\\\n\u001b[0;32m---> 32\u001b[0;31m                           model,crit_comp,optimizer,lr,lambd_,nb_epochs=nb_epochs,verbose=verbose)\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_double_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_targ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#0th column: 1st group acc 1th column 2nd group acc 3rd column comp accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-986f9d5d6818>\u001b[0m in \u001b[0;36mtrain_double_model\u001b[0;34m(train_input, train_target, train_classes, model, crit_comp, optimizer, lr, lambd_, nb_epochs, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mtotloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_comp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mtotloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "linGRID = lin_view(HYPER_GRID)[:2]\n",
    "GridSearch(linGRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMax(HYPER_GRID):\n",
    "    return max(lin_view(HYPER_GRID),key = lambda x:x.score_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparam = GetMax(HYPER_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:96.00\n",
      "####################Train accuracy:####################\n",
      "Accuracy 1st Network:    0.14   \n",
      "Accuracy 2nd Network:    0.13   \n",
      "Accuracy comparison:     0.47    \n",
      "####################Test accuracy:####################\n",
      "Accuracy 1st Network:    0.11   \n",
      "Accuracy 2nd Network:    0.14   \n",
      "Accuracy comparison:     0.45    \n"
     ]
    }
   ],
   "source": [
    "net,loss,opt,lr,lambd = bestparam.get_params()\n",
    "net_dropout = WeightAux()\n",
    "train_double_model(train2_input,train2_target,train2_classes,\\\n",
    "                   net,loss,opt,lr=lr,lambd_=lambd,nb_epochs=25,verbose=True)\n",
    "print(sep + \"Train accuracy:\" + sep)\n",
    "accuracy_double_model(net,train2_input,train2_target,train2_classes,verbose=True)\n",
    "print(sep+ \"Test accuracy:\" + sep)\n",
    "_ = accuracy_double_model(net,test2_input,test2_target,test2_classes,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START<br>\n",
    "Generate the initial population<br>\n",
    "Compute fitness<br>\n",
    "REPEAT<br>\n",
    "    Selection<br>\n",
    "    Crossover<br>\n",
    "    Mutation<br>\n",
    "    Compute fitness<br>\n",
    "UNTIL population has converged<br>\n",
    "STOP<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption: complex : hill climbing algorithm might get stuck in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply elitist selection with hyper-hyper parameter ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(n_pop=100):\n",
    "    population = [Param() for _ in range(n_pop)]\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_individuality(population):\n",
    "    count_matrix = [{i:0 for i in param} for param in Param.hyper_params]\n",
    "    for ind in population:\n",
    "        for val,dico in zip(ind.params.values(),count_matrix):\n",
    "            if not val in dico:\n",
    "                dico[val] = 0\n",
    "            dico[val] += 1\n",
    "    for ind in population:\n",
    "        diffs = []\n",
    "        for val,dico in zip(ind.params.values(),count_matrix):\n",
    "            diffs.append(sum(dico.values()) - dico[val])\n",
    "        indiv = (1/(sum([1/diff if diff!=0 else 6 for diff in diffs])))\n",
    "        ind.individuality = indiv\n",
    "    individualities = [ind.individuality for ind in population]\n",
    "    maxo,mino = max(individualities),min(individualities)\n",
    "    if maxo != mino:\n",
    "        for ind in population:\n",
    "            ind.individuality = (ind.individuality - mino)/(maxo-mino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fitness(population,K=5,verbose=False):\n",
    "     for ind in population:\n",
    "            if ind.score_mean == -1:\n",
    "                ind.KFold(K=K,verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population,selec_ratio=0.5,lambd_ =0.2):\n",
    "    #sort population\n",
    "    top_decreas = sorted(population,key=lambda x: x.score_mean + lambd_ * x.individuality)[::-1]\n",
    "    return top_decreas[:int((len(population)*selec_ratio))]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed(top_pop,n_pop=100,N_CHANCE=50):\n",
    "    assert(n_pop >= len(top_pop))\n",
    "    top_pop = copy.deepcopy(top_pop)\n",
    "    n_top = len(top_pop)\n",
    "    n_miss = n_pop - n_top\n",
    "    for i in range(n_miss):\n",
    "        parindx1,parindx2 = torch.randperm(n_top).tolist()[:2]\n",
    "        par1 = top_pop[parindx1]\n",
    "        par2 = top_pop[parindx2]\n",
    "        params1 = par1.get_params()\n",
    "        params2 = par2.get_params()\n",
    "        n_params = len(params1)\n",
    "        bits = torch.randint(2,(n_params,)).tolist()\n",
    "        params = [par1 if bit == 0 else par2 for par1,par2,bit in zip(params1,params2,bits)]\n",
    "        child = Param(*params)\n",
    "        n_rand = torch.randint(N_CHANCE,(1,)).item()\n",
    "        if n_rand == 0:\n",
    "            print(\"mutation!\")\n",
    "            child.mutate()\n",
    "        top_pop.append(child)\n",
    "    return top_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_population(population):\n",
    "    N = len(population)\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.bar(range(N),[ind.score_mean for ind in population])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:80.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-6e38a1d4f6a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_indiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_POP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcompute_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcompute_individuality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_ITER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-c6ff2932f93b>\u001b[0m in \u001b[0;36mcompute_fitness\u001b[0;34m(population, K, verbose)\u001b[0m\n\u001b[1;32m      2\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_mean\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-b288e47b08fa>\u001b[0m in \u001b[0;36mKFold\u001b[0;34m(self, K, verbose)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambd_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         scores = Kfold_CVdouble(train2_input,train2_target,train2_classes,\\\n\u001b[0;32m---> 42\u001b[0;31m                 arch,loss,opt,lr,lambd_,K=K,verbose=verbose)\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-b5a7ad1117e4>\u001b[0m in \u001b[0;36mKfold_CVdouble\u001b[0;34m(inputs, targets, classes, model_template, crit_comp, optimizer, lr, lambd_, K, nb_epochs, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         train_double_model(train_inp,train_targ,train_classes,\\\n\u001b[0;32m---> 32\u001b[0;31m                           model,crit_comp,optimizer,lr,lambd_,nb_epochs=nb_epochs,verbose=verbose)\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_double_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_targ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#0th column: 1st group acc 1th column 2nd group acc 3rd column comp accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-986f9d5d6818>\u001b[0m in \u001b[0;36mtrain_double_model\u001b[0;34m(train_input, train_target, train_classes, model, crit_comp, optimizer, lr, lambd_, nb_epochs, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mtotloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_comp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mtotloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_POP = 10\n",
    "N_ITER = 100\n",
    "best_indiv = Param()\n",
    "population = generate_population(N_POP)\n",
    "compute_fitness(population,K=2,verbose=True)\n",
    "compute_individuality(population)\n",
    "for i in range(N_ITER):\n",
    "    clear_output(wait=False)\n",
    "    print(\"Population Progression: {} %\".format(i/N_ITER * 100))\n",
    "    plot_population(population)\n",
    "    plt.pause(0.05)\n",
    "    population = selection(population,selec_ratio=0.6)\n",
    "    if population[0].score_mean > best_indiv.score_mean:\n",
    "        best_indiv = population[0]\n",
    "    population = breed(population,N_POP,N_CHANCE=10)\n",
    "    compute_fitness(population,K=2)\n",
    "    compute_individuality(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d,e = population[6].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:16.00\n"
     ]
    }
   ],
   "source": [
    "Kfold_CVdouble(train2_input,train2_target,train2_classes,\\\n",
    "               a,b,c,d,e,K=5,nb_epochs=25,verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
