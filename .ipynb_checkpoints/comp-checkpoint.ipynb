{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import pickle\n",
    "import math\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import dlc_practical_prologue as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = dl.load_data(flatten=False)\n",
    "train_input = torch.functional.F.avg_pool2d(train_input, kernel_size = 2)\n",
    "test_input = torch.functional.F.avg_pool2d(test_input, kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.block1 = nn.Sequential(nn.Conv2d(1,32, kernel_size=5,stride=1),\n",
    "                                    nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    nn.ReLU())\n",
    "        self.block2 = nn.Sequential(nn.Conv2d(32,16, kernel_size=5,stride=1),\n",
    "                                    nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                    nn.BatchNorm2d(16),\n",
    "                                    nn.ReLU())\n",
    "        self.lins = nn.Sequential(nn.Linear(256, 84),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(84, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.lins(x.view(-1,256))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,inputs,targets):\n",
    "    assert(inputs.size(0) == targets.size(0))\n",
    "    tot_loss = 0\n",
    "    nb_correct = 0\n",
    "    batch_size = 20\n",
    "    for train,target in zip(inputs.split(batch_size),\n",
    "                           targets.split(batch_size)):\n",
    "        pred = model(train)\n",
    "        pred = torch.argmax(pred,axis = 1)\n",
    "        nb_correct += (pred == target).int().sum().item()\n",
    "    accuracy = nb_correct /inputs.size(0)\n",
    "    print(\"accuracy: %.2f\" % (accuracy) )\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_input,train_target,nb_epochs=25):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr = 1e-3)\n",
    "    batch_size = 100\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for e in range(nb_epochs):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Progression:{:.2f}\".format(e/nb_epochs*100))\n",
    "        for inputs,targets in zip(train_input.split(batch_size),\n",
    "                            train_target.split(batch_size)):\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output,targets)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self,n_hidden = 256,chan = 1):\n",
    "        super(Net2,self).__init__()\n",
    "        self.hidden = n_hidden\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(chan,32,kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            ,nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256,n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.Linear(n_hidden,10))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.classifier(x.view(x.size(0),-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:96.00\n",
      "accuracy: 0.93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.934"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net2()\n",
    "train_model(model,train_input,train_target)\n",
    "get_accuracy(model,test_input,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kfold_CV(classtype,inputs,targets,K=4):\n",
    "    assert(K>=2)\n",
    "    N = inputs.size(0)\n",
    "    indxes = torch.randperm(N)\\\n",
    "                  .split(int(N/K))\n",
    "    accs = torch.empty(K)\n",
    "    for k in range(K):\n",
    "        model = classtype()\n",
    "        \n",
    "        test_indx = indxes[k]\n",
    "        train_indx = torch.cat((indxes[:k]+indxes[k+1:]),0)\n",
    "        \n",
    "        train_inp,train_targ = inputs[train_indx],targets[train_indx]\n",
    "        test_inp,test_targ = inputs[test_indx],targets[test_indx]\n",
    "        train_model(model,train_inp,train_targ)\n",
    "        acc = get_accuracy(model,test_inp,test_targ)\n",
    "        accs[k] = acc\n",
    "    print(\"Accuracies for {}-fold:{}\".format(K,accs.tolist()))\n",
    "    print(\"Mean acc:{}\".format(accs.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:96.00\n",
      "accuracy: 0.93\n",
      "Accuracies for 4-fold:[0.9160000085830688, 0.9079999923706055, 0.9359999895095825, 0.9319999814033508]\n",
      "Mean acc:0.9229999780654907\n"
     ]
    }
   ],
   "source": [
    "Kfold_CV(Net2,train_input,train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with double Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"#\" * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_double_model(model,train_input,train_target,train_classes,verbose=False):\n",
    "    assert(train_input.size(0) == train_target.size(0))\n",
    "    N = train_input.size(0)\n",
    "    tot_loss = 0\n",
    "    nb_correct = 0\n",
    "    batch_size = 20\n",
    "    \n",
    "    #given a prediction powre and the target, output the number of correctly classified samples\n",
    "    add_res = lambda pred,target:(torch.argmax(pred,axis = 1) == target).int().sum().item()\n",
    "    \n",
    "    score0 = 0\n",
    "    score1 = 0\n",
    "    scorecomp = 0\n",
    "    \n",
    "    for inputs,comp_targs,classes in zip(train_input.split(batch_size),\n",
    "                                           train_target.split(batch_size),\n",
    "                                        train_classes.split(batch_size)):\n",
    "        targ0 = classes[:,0]\n",
    "        targ1 = classes[:,1]\n",
    "        x0,x1,comp = model(inputs)\n",
    "        \n",
    "        score0 += add_res(x0,targ0)\n",
    "        score1 += add_res(x1,targ1)\n",
    "        scorecomp += add_res(comp,comp_targs)\n",
    "        \n",
    "    acc0 = score0 / N\n",
    "    acc1 = score1 / N\n",
    "    acc_comp = scorecomp / N\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Accuracy 1st Network: {:^10.2f}\".format(acc0) )\n",
    "        print(\"Accuracy 2nd Network: {:^10.2f}\".format(acc1))\n",
    "        print(\"Accuracy comparison: {:^12.2f}\".format(acc_comp))\n",
    "\n",
    "    return acc0,acc1,acc_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet2imgs(nn.Module):\n",
    "    def __init__(self,chan = 1):\n",
    "        super(LeNet2imgs,self).__init__()\n",
    "        self.net0 = Net2()\n",
    "        self.net1 = Net2()\n",
    "        self.linblock = nn.Sequential(nn.Linear(20,40),\n",
    "                                     nn.LeakyReLU(),\n",
    "                                     nn.Linear(40,80),\n",
    "                                     nn.LeakyReLU(),\n",
    "                                     nn.Linear(80,2))\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x0 = self.net0(x[:,0].unsqueeze(1))\n",
    "        x1 = self.net0(x[:,1].unsqueeze(1))\n",
    "        comp = torch.cat((x0,x1),dim=1)\n",
    "        comp = self.linblock(comp)\n",
    "        return x0,x1,comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_double_model(train_input,train_target,train_classes,\\\n",
    "                       model,crit_comp,optimizer,lr,lambd_,nb_epochs=5,verbose=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: the model to train (3 arch)\n",
    "        crit_comp: the criterion for comparison (2 sorts)\n",
    "        optimizer: the chosen optimizer (3 types)\n",
    "        lr: learning rate (4 types)\n",
    "        ratio loss: the amount of each loss (3 values)\n",
    "        lambd_: ratio lambd_ * comp_loss + (1-lambd_) * class_loss\n",
    "    \"\"\"\n",
    "    crit_comp = crit_comp()\n",
    "    optimizer = optimizer(model.parameters(), lr = lr)\n",
    "\n",
    "    batch_size = 100\n",
    "    crit_class = nn.CrossEntropyLoss()\n",
    "    for e in range(nb_epochs):\n",
    "        if verbose:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Progression:{:.2f}\".format(e/nb_epochs*100))\n",
    "        for inputs,comp_targs,classes in zip(train_input.split(batch_size),\n",
    "                                           train_target.split(batch_size),\n",
    "                                           train_classes.split(batch_size)):\n",
    "            targ0 = classes[:,0]\n",
    "            targ1 = classes[:,1]\n",
    "            x0,x1,comp = model(inputs)\n",
    "            loss_class = crit_class(x0,targ0) + crit_class(x1,targ1)\n",
    "            loss_comp = crit_comp(comp,comp_targs)\n",
    "            totloss = lambd_ * loss_comp + (1- lambd_) *loss_class\n",
    "            model.zero_grad()\n",
    "            totloss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 500\n",
    "a, b, c, d = dl.load_data(flatten=False)\n",
    "train2_input, train2_target, train2_classes = dl.mnist_to_pairs(N_SAMPLES,a,b)\n",
    "test2_input, test2_target, test2_classes = dl.mnist_to_pairs(N_SAMPLES,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kfold_CVdouble(inputs,targets,classes,\\\n",
    "                   archi,crit_comp,optimizer,lr,lambd_,K=4,verbose=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        archi: the type of architecture for classif (3 arch)\n",
    "        crit_comp: the criterion for comparison (2 sorts)\n",
    "        optimizer: the chosen optimizer (3 types)\n",
    "        lr: learning rate (4 types)\n",
    "        ratio loss: the amount of each loss (3 values)\n",
    "        lambd_: ratio lambd_ * comp_loss + (1-lambd_) * class_loss\n",
    "    \"\"\"\n",
    "    assert(K>=2)\n",
    "    N = inputs.size(0)\n",
    "    indxes = torch.randperm(N)\\\n",
    "                  .split(int(N/K))\n",
    "    accs = torch.empty(K,3)\n",
    "    for k in range(K):\n",
    "        model = archi()\n",
    "        \n",
    "        test_indx = indxes[k]\n",
    "        train_indx = torch.cat((indxes[:k]+indxes[k+1:]),0)\n",
    "        \n",
    "        train_inp = inputs[train_indx]\n",
    "        train_targ = targets[train_indx]\n",
    "        train_classes = classes[train_indx]\n",
    "        \n",
    "        test_inp  = inputs[test_indx]\n",
    "        test_targ = targets[test_indx]\n",
    "        test_classes = classes[test_indx]\n",
    "        \n",
    "        train_double_model(train_inp,train_targ,train_classes,\\\n",
    "                          model,crit_comp,optimizer,lr,lambd_,verbose=verbose)\n",
    "        res = accuracy_double_model(model,test_inp,test_targ,test_classes)\n",
    "        #0th column: 1st group acc 1th column 2nd group acc 3rd column comp accuracy\n",
    "        accs[k] = torch.Tensor(res)\n",
    "    if verbose:\n",
    "        print(sep + \"Accuracies for {}-fold:\".format(K) + sep)\n",
    "        print(\"1st group acc:{:^14.2f}\".format(accs[:,0].mean().item()))\n",
    "        print(\"2nd group acc:{:^14.2f}\".format(accs[:,1].mean().item()))\n",
    "        print(\"Comparison acc:{:^12.2f}\".format(accs[:,2].mean().item()))\n",
    "    return accs[:,2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:80.00\n",
      "####################Accuracies for 5-fold:####################\n",
      "1st group acc:     0.85     \n",
      "2nd group acc:     0.86     \n",
      "Comparison acc:    0.81    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.800000011920929,\n",
       " 0.8299999833106995,\n",
       " 0.6899999976158142,\n",
       " 0.8700000047683716,\n",
       " 0.8799999952316284]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kfold_CVdouble(train2_input,train2_target,train2_classes,\\\n",
    "               LeNet2imgs,nn.CrossEntropyLoss,optim.SGD,1e-0,0.75,K=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:96.00\n",
      "####################Train accuracy:####################\n",
      "Accuracy 1st Network:    1.00   \n",
      "Accuracy 2nd Network:    1.00   \n",
      "Accuracy comparison:     1.00    \n",
      "####################Test accuracy:####################\n",
      "Accuracy 1st Network:    0.92   \n",
      "Accuracy 2nd Network:    0.93   \n",
      "Accuracy comparison:     0.84    \n"
     ]
    }
   ],
   "source": [
    "net2 = LeNet2imgs()\n",
    "train_double_model(train2_input,train2_target,train2_classes,\\\n",
    "                   net2,nn.CrossEntropyLoss,optim.SGD,1e-0,0.75,nb_epochs=25)\n",
    "print(sep + \"Train accuracy:\" + sep)\n",
    "accuracy_double_model(net2,train2_input,train2_target,train2_classes,verbose=True)\n",
    "print(sep+ \"Test accuracy:\" + sep)\n",
    "_ = accuracy_double_model(net2,test2_input,test2_target,test2_classes,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Architecture\n",
    "Archis = [LeNet2imgs]\n",
    "#2 Comparison Loss Function\n",
    "CompLoss = [nn.CrossEntropyLoss,nn.MSELoss]\n",
    "#3 Optimizers\n",
    "Optimizers = [optim.SGD,optim.Adam,optim.Adagrad,optim.AdamW]\n",
    "#4 Learning Rates\n",
    "LRs = [1e-4,1e-3,1e-2,1e-1,1]\n",
    "#5 Ratios\n",
    "Lambdas = [0.4,0.7,0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param():\n",
    "    @staticmethod\n",
    "    def parse(classi):\n",
    "        return str(classi).split('.')[-1].split(\"'\")[0]\n",
    "    def __init__(self,arch,loss,optim,lr,lambd_):\n",
    "        self.arch = arch\n",
    "        self.loss = loss\n",
    "        self.optim = optim\n",
    "        self.lr = lr\n",
    "        self.lambd_ = lambd_\n",
    "        self.params = [self.arch,self.loss,self.optim,self.lr,self.lambd_]\n",
    "        self.score = -1\n",
    "    def __str__(self):\n",
    "        returned = \"{}_{}_{}_{}_{}_#score#_{}\".format(Param.parse(self.arch),\n",
    "                                               Param.parse(self.loss),\n",
    "                                               Param.parse(self.optim),\n",
    "                                               self.lr,\n",
    "                                               self.lambd_,\n",
    "                                               self.score)\n",
    "        return returned\n",
    "    def __repr__(self):\n",
    "        return str(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER_GRID = torch.empty(len(Archis),len(CompLoss),len(Optimizers),len(LRs),len(Lambdas)).tolist()\n",
    "for a,archi in enumerate(Archis):\n",
    "    for b,loss in enumerate(CompLoss):\n",
    "        for c,optim in enumerate(Optimizers):\n",
    "            for d,lr in enumerate(LRs):\n",
    "                for e,lambd_ in enumerate(Lambdas):\n",
    "                    HYPER_GRID[a][b][c][d][e] = Param(archi,loss,optim,lr,lambd_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_view(HYPER_GRID):\n",
    "    linHGRID = [e for a in HYPER_GRID for b in a for c in b for d in c for e in d]\n",
    "    return linHGRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet2imgs_CrossEntropyLoss_SGD_0.0001_0.4_#score#_-1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_view(HYPER_GRID)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch(HYPER_GRID):\n",
    "    linGRID = lin_view(HYPER_GRID)\n",
    "    for i,param in enumerate(linGRID):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Grid Search progression: {} %\".format(i/len(linGRID)*100))\n",
    "        arch,loss,opt,lr,lambds_ = param.params\n",
    "        Kfold_CVdouble(train2_input,train2_target,train2_classes,\\\n",
    "                arch,loss,opt,lr,lambds_,K=5,verbose=False) \n",
    "    \n",
    "    with open('HYPERPARAM.pkl', 'wb') as f:\n",
    "        pickle.dump(HYPER_GRID,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search progression: 0.0 %\n",
      "Grid Search progression: 0.8333333333333334 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-4aec7720761e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHYPER_GRID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-b22ca2ea1af3>\u001b[0m in \u001b[0;36mGridSearch\u001b[0;34m(HYPER_GRID)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambds_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         Kfold_CVdouble(train2_input,train2_target,train2_classes,\\\n\u001b[0;32m----> 7\u001b[0;31m                 arch,loss,opt,lr,lambds_,K=5,verbose=False) \n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-028bd9cd4b62>\u001b[0m in \u001b[0;36mKfold_CVdouble\u001b[0;34m(inputs, targets, classes, archi, crit_comp, optimizer, lr, lambd_, K, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         train_double_model(train_inp,train_targ,train_classes,\\\n\u001b[0;32m---> 32\u001b[0;31m                           model,crit_comp,optimizer,lr,lambd_,verbose=verbose)\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_double_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_targ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#0th column: 1st group acc 1th column 2nd group acc 3rd column comp accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-43398a5f219c>\u001b[0m in \u001b[0;36mtrain_double_model\u001b[0;34m(train_input, train_target, train_classes, model, crit_comp, optimizer, lr, lambd_, nb_epochs, verbose)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtarg0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtarg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mloss_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcrit_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit_comp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomp_targs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-45f91349d892>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2ddeb605ee8e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    140\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 488\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GridSearch(HYPER_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
