{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import dlc_practical_prologue as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = dl.load_data(flatten=False)\n",
    "train_input = torch.functional.F.avg_pool2d(train_input, kernel_size = 2)\n",
    "test_input = torch.functional.F.avg_pool2d(test_input, kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.block1 = nn.Sequential(nn.Conv2d(1,32, kernel_size=5,stride=1),\n",
    "                                    nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    nn.ReLU())\n",
    "        self.block2 = nn.Sequential(nn.Conv2d(32,16, kernel_size=5,stride=1),\n",
    "                                    nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                    nn.BatchNorm2d(16),\n",
    "                                    nn.ReLU())\n",
    "        self.lins = nn.Sequential(nn.Linear(256, 84),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(84, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.lins(x.view(-1,256))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self,n_hidden = 100,chan = 1):\n",
    "        super(Net2,self).__init__()\n",
    "        self.hidden = n_hidden\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(chan,32,kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            ,nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2,n_hidden),\n",
    "           # nn.Dropout(0.5),\n",
    "            nn.Linear(n_hidden,10)\n",
    "            #nn.Softmax2d()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.classifier(x.view(x.size(0),-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_input,train_target,nb_epochs=5):\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "    batch_size = 100\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for e in range(nb_epochs):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Progression:{:.2f}\".format(e/nb_epochs*100))\n",
    "        for inputs,targets in zip(train_input.split(batch_size),\n",
    "                            train_target.split(batch_size)):\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output,targets)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,inputs,targets):\n",
    "    assert(inputs.size(0) == targets.size(0))\n",
    "    tot_loss = 0\n",
    "    nb_correct = 0\n",
    "    batch_size = 20\n",
    "    for train,target in zip(inputs.split(batch_size),\n",
    "                           targets.split(batch_size)):\n",
    "        pred = model(train)\n",
    "        pred = torch.argmax(pred,axis = 1)\n",
    "        nb_correct += (pred == target).int().sum().item()\n",
    "    accuracy = nb_correct /inputs.size(0)\n",
    "    print(\"accuracy: %.2f\" % (accuracy) )\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kfold_CV(classtype,inputs,targets,K=4):\n",
    "    assert(K>=2)\n",
    "    N = inputs.size(0)\n",
    "    indxes = torch.randperm(N)\\\n",
    "                  .split(int(N/K))\n",
    "    accs = torch.empty(K)\n",
    "    for k in range(K):\n",
    "        model = classtype()\n",
    "        \n",
    "        test_indx = indxes[k]\n",
    "        train_indx = torch.cat((indxes[:k]+indxes[k+1:]),0)\n",
    "        \n",
    "        train_inp,train_targ = inputs[train_indx],targets[train_indx]\n",
    "        test_inp,test_targ = inputs[test_indx],targets[test_indx]\n",
    "        train_model(model,train_inp,train_targ)\n",
    "        acc = get_accuracy(model,train_inp,train_targ)\n",
    "        accs[k] = acc\n",
    "    print(\"Accuracies for {}-fold:{}\".format(K,accs.tolist()))\n",
    "    print(\"Mean acc:{}\".format(accs.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:80.00\n",
      "accuracy: 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net2()\n",
    "train_model(model,train_input,train_target)\n",
    "get_accuracy(model,train_input,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:80.00\n",
      "accuracy: 0.99\n",
      "Accuracies for 4-fold:[0.9866666793823242, 0.9879999756813049, 0.9906666874885559, 0.9893333315849304]\n",
      "Mean acc:0.9886666536331177\n"
     ]
    }
   ],
   "source": [
    "Kfold_CV(Net2,train_input,train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with double Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "a, b, c, d = dl.load_data(flatten=False)\n",
    "train2_input, train2_target, train2_classes = dl.mnist_to_pairs(28,a,b)\n",
    "test2_input, test2_target, test2_classes = dl.mnist_to_pairs(28,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 2, 0, 7, 9, 3, 1, 0, 3, 4, 8, 2, 8, 0, 8, 8, 3, 9, 4, 7, 7, 9, 9,\n",
       "        7, 3, 6, 0])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_classes[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9574, 0.8164],\n",
       "        [0.6936, 0.4115],\n",
       "        [0.3574, 0.7729],\n",
       "        [0.8452, 0.5438],\n",
       "        [0.6778, 0.6991],\n",
       "        [0.8857, 0.2749],\n",
       "        [0.7880, 0.4802],\n",
       "        [0.1622, 0.6052],\n",
       "        [0.1941, 0.2088]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.rand(3,2),torch.rand(6,2)),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet2imgs(nn.Module):\n",
    "    def __init__(self,chan = 1):\n",
    "        super(LeNet2imgs,self).__init__()\n",
    "        self.net0 = Net2()\n",
    "        self.net1 = Net2()\n",
    "        self.linblock = nn.Sequential(nn.Linear(20,2),\n",
    "                                      nn.ReLU())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x0 = self.net0(x[:,0].unsqueeze(1))\n",
    "        x1 = self.net1(x[:,1].unsqueeze(1))\n",
    "        comp = torch.cat((x0,x1),dim=1)\n",
    "        comp = self.linblock(comp)\n",
    "        return x0,x1,comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = LeNet2imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train2_input[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-6.3500e-01,  2.1712e-01,  1.9979e-01,  6.4478e-01,  9.3705e-02,\n",
       "          -1.4389e-01,  3.3843e-01,  1.8287e-01, -6.8561e-02,  1.0964e-01],\n",
       "         [-7.4665e-01,  1.5814e-01,  3.7123e-02,  5.8379e-01,  2.8070e-01,\n",
       "          -2.6475e-01,  4.1695e-02,  4.3801e-01, -8.3131e-03,  5.5023e-01],\n",
       "         [-2.4485e-01,  5.2345e-01, -6.8252e-03,  2.6208e-01, -5.2334e-01,\n",
       "          -1.1947e-01,  2.0169e-01, -1.1570e-01,  1.1686e-01,  3.4315e-01],\n",
       "         [-3.5936e-01,  1.5088e-01,  4.9007e-02,  5.6661e-01, -8.4083e-01,\n",
       "           4.1519e-02, -5.7859e-01, -4.2253e-02, -1.5741e-01,  4.2106e-01],\n",
       "         [-2.3804e-01,  2.1723e-01, -6.9425e-02,  5.1032e-01,  2.5273e-01,\n",
       "           2.8984e-01,  1.5738e-01,  3.1906e-02,  1.9539e-01, -2.3209e-01],\n",
       "         [-2.0402e-01,  3.7970e-02,  2.8363e-02,  3.6457e-01,  3.4531e-01,\n",
       "           1.8474e-01,  2.6056e-01, -6.4407e-02, -2.9155e-01, -4.8341e-01],\n",
       "         [ 1.6206e-01,  5.9672e-01,  3.9365e-01,  6.2981e-01, -1.5756e-01,\n",
       "          -3.6091e-01, -5.2206e-01,  6.8024e-02, -9.3212e-02,  8.5207e-02],\n",
       "         [ 3.5311e-02,  1.8448e-01, -1.1964e-01,  2.1730e-01, -6.4268e-01,\n",
       "          -5.2547e-01, -2.1606e-01, -1.9726e-01,  3.0208e-02,  4.3223e-01],\n",
       "         [-6.5498e-03, -1.7919e-01,  1.1795e-01,  1.6467e-01,  3.0675e-01,\n",
       "           5.0311e-01,  3.3362e-01,  2.9008e-01,  2.6143e-01, -2.9167e-01],\n",
       "         [ 6.9838e-01,  5.6901e-01, -1.4414e-01,  5.6911e-01, -9.9873e-02,\n",
       "           2.7000e-01, -1.0138e-02,  1.3684e-01,  7.6582e-02,  4.2802e-02],\n",
       "         [-2.1198e-01,  3.2267e-01,  3.3618e-01,  2.5139e-01,  4.0229e-01,\n",
       "           4.7170e-01,  1.1830e-01, -2.9549e-02, -8.3273e-02, -1.6152e-01],\n",
       "         [-3.5755e-01,  2.8482e-01,  1.5351e-01,  6.6551e-01, -3.2759e-02,\n",
       "          -2.4238e-01, -3.6053e-02,  2.5500e-01,  2.5207e-01, -4.6914e-02],\n",
       "         [ 8.8502e-02,  6.9525e-02, -2.1630e-01,  5.3265e-01,  1.6322e-01,\n",
       "           3.2906e-01,  3.0095e-03,  3.5383e-01,  1.0665e-01, -2.8842e-01],\n",
       "         [ 2.0829e-01,  7.4151e-01,  6.4233e-03, -9.0601e-02, -4.6904e-01,\n",
       "           4.8660e-02,  7.4370e-01, -2.7277e-01, -9.8182e-02,  3.8831e-01],\n",
       "         [-3.8761e-02,  4.9611e-01, -3.7706e-02,  5.3681e-01,  3.7524e-01,\n",
       "          -5.1078e-01,  4.2352e-01, -9.2028e-03,  4.2613e-02, -2.4856e-01],\n",
       "         [ 4.7476e-02, -2.0033e-01,  2.1837e-01,  6.9080e-01, -7.0133e-02,\n",
       "           1.6930e-01, -3.3289e-01, -7.1346e-01,  2.5720e-01, -3.7544e-01],\n",
       "         [-1.5791e-02,  8.7965e-02, -1.8832e-02,  3.1741e-01,  6.3139e-02,\n",
       "          -4.3123e-01, -4.7670e-01,  1.9861e-01, -4.5203e-01,  2.1538e-01],\n",
       "         [-5.6729e-02,  2.0827e-01, -1.9494e-01, -1.4173e-01, -5.2320e-02,\n",
       "           6.6046e-02,  9.2140e-02, -2.5866e-01, -6.4757e-01, -4.5863e-01],\n",
       "         [-2.7947e-01,  1.0572e+00, -1.4112e-01,  1.6127e-01, -8.5764e-01,\n",
       "          -4.2285e-01, -6.5337e-02, -5.5979e-01, -3.9057e-02,  7.3325e-01],\n",
       "         [-6.6751e-01,  3.6919e-01, -1.9854e-01,  3.4128e-01, -3.6142e-01,\n",
       "          -2.5212e-01, -2.1892e-01,  9.2593e-02, -3.2215e-01,  5.4764e-01],\n",
       "         [-4.3102e-01,  3.4872e-01,  1.0085e-03,  8.1241e-01,  1.9889e-01,\n",
       "          -2.2150e-01,  1.0956e-01,  2.2873e-01, -2.0626e-01,  4.2368e-01],\n",
       "         [-3.8399e-01,  5.6546e-01, -4.2617e-01, -1.8554e-02, -1.9519e-03,\n",
       "          -8.1590e-01,  1.5617e-01,  4.1799e-01, -3.0100e-01,  3.7491e-01],\n",
       "         [ 2.7085e-02,  3.1953e-02,  9.7621e-02,  2.6084e-01, -1.3402e-01,\n",
       "           4.0909e-01,  2.5360e-01, -1.3972e-01,  1.0574e-01, -1.4326e-01],\n",
       "         [-7.1996e-02,  2.4948e-01,  7.3759e-02,  6.5937e-01,  2.2260e-01,\n",
       "          -2.9871e-01,  3.0534e-01,  1.7247e-02, -2.5021e-02, -2.1826e-02],\n",
       "         [-1.0865e-01,  4.0312e-01,  1.6968e-01,  5.1638e-01, -2.9999e-01,\n",
       "          -2.8276e-01, -4.4988e-01, -4.1127e-02, -5.4217e-02,  3.4537e-01],\n",
       "         [ 4.0991e-01,  8.5875e-01, -5.8876e-02,  2.7578e-02, -1.2155e-01,\n",
       "          -3.6696e-01,  5.1885e-01, -5.9140e-02,  3.3240e-01, -6.4590e-01],\n",
       "         [-1.7079e-01,  7.5792e-01, -2.0002e-03,  4.1885e-01, -1.8271e-01,\n",
       "          -1.8582e-01,  4.3832e-01, -3.9731e-01,  2.9105e-01, -8.2423e-02],\n",
       "         [ 9.4888e-01, -3.2255e-01, -1.7052e-01,  4.6544e-01,  6.1990e-02,\n",
       "           5.6105e-01,  5.9330e-02, -1.2966e-01,  8.8134e-01, -8.4909e-01]],\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[ 0.0058,  0.3927, -0.2681,  0.6263, -0.3273, -0.2913, -0.4354, -0.1508,\n",
       "          -0.3539,  0.1034],\n",
       "         [ 0.5582, -0.2367,  0.6832,  0.0204,  0.3881, -0.1627, -0.6986,  0.6102,\n",
       "          -0.0919, -0.1070],\n",
       "         [ 0.2372,  0.1806, -0.0516,  0.6694, -0.0548,  0.3589, -0.4600, -0.5307,\n",
       "          -0.2296,  0.2952],\n",
       "         [ 0.1659,  0.4073,  0.3185, -0.2623,  0.2334, -0.5280, -0.3805,  0.3703,\n",
       "          -0.6479, -0.2876],\n",
       "         [-0.1761,  0.5396, -0.3696,  0.4245, -0.2244, -0.5222, -0.3132,  0.2564,\n",
       "          -0.4030, -0.4787],\n",
       "         [-0.1505, -0.2085, -0.0104,  0.3291,  0.0490, -0.1104, -0.5992, -0.0714,\n",
       "           0.0251,  0.2713],\n",
       "         [ 0.4800,  0.0810,  0.5007,  0.5255,  0.2483, -0.1382, -0.5066, -0.2905,\n",
       "          -0.1260,  0.1888],\n",
       "         [-0.1512,  0.3429, -0.2468, -0.1513, -0.6814, -0.1228, -0.2820, -0.8723,\n",
       "           0.2131, -0.3510],\n",
       "         [-0.2512,  0.1062, -0.0247,  0.0135, -0.2810, -0.0468, -0.5526, -0.2760,\n",
       "           0.7820, -0.0386],\n",
       "         [ 0.0681,  0.2921,  0.0073,  0.0263, -0.2388, -0.5120, -0.3605,  0.5367,\n",
       "          -0.6018, -0.2158],\n",
       "         [-0.0980, -0.0256,  0.3050,  0.1784, -0.2398, -0.2939, -0.0260, -0.2922,\n",
       "          -0.1854, -0.2646],\n",
       "         [-0.0508,  0.5183,  0.0144,  0.0348, -0.2353, -0.4762, -0.2184,  0.0589,\n",
       "          -0.0709, -0.5538],\n",
       "         [ 0.0612, -0.2188,  0.0916,  0.2522, -0.0764, -0.2905, -0.7428,  0.3890,\n",
       "           0.2475,  0.3260],\n",
       "         [-0.2189, -0.3462,  0.5393,  0.3779,  0.3416, -0.0252, -0.4329, -0.2788,\n",
       "          -0.1798,  0.5467],\n",
       "         [ 0.3114, -0.0981, -0.0420, -0.1830, -0.6067, -0.1776, -0.0654, -0.7882,\n",
       "           0.6687, -0.3153],\n",
       "         [ 0.7890, -0.1532,  0.0734,  0.2283, -0.4712, -0.4196, -0.3104, -0.2649,\n",
       "          -0.0769,  0.1379],\n",
       "         [ 0.2334,  0.5560, -0.0220,  0.7424, -0.1320, -0.1951,  0.0346, -0.4620,\n",
       "          -0.5254, -0.2210],\n",
       "         [ 0.6966,  0.3693,  0.5734, -0.7515, -0.2780, -0.2640,  0.1880, -0.2234,\n",
       "          -0.2198, -0.4075],\n",
       "         [-0.1519,  0.0238,  0.0908,  0.0737, -0.1987,  0.1307, -0.4233, -0.1731,\n",
       "           0.3160, -0.2161],\n",
       "         [-0.3132, -0.3719,  0.3864,  0.5467,  0.2826, -0.6622, -0.3732, -0.4448,\n",
       "           0.2825, -0.0082],\n",
       "         [ 0.3516,  0.3710,  0.2514, -0.4450,  0.0354, -0.0716,  0.2204, -0.1994,\n",
       "           0.0997, -0.8415],\n",
       "         [ 0.3392,  0.6419, -0.2343, -0.1645, -0.5270, -0.3104,  0.4183, -0.1985,\n",
       "          -0.6788, -0.6221],\n",
       "         [-0.2679, -0.1245, -0.2455,  0.7089, -0.2606, -0.5236, -0.1455, -0.4308,\n",
       "           1.0719, -0.7575],\n",
       "         [ 0.3534,  0.1715, -0.1410, -0.0147, -0.2710,  0.0997, -0.0874, -0.3164,\n",
       "           0.2189, -0.2349],\n",
       "         [-0.1850, -0.4110,  0.3159,  0.1650,  0.1627, -0.3839, -0.3093, -0.5538,\n",
       "           0.4190,  0.0044],\n",
       "         [-0.6946, -0.1343,  0.1326, -0.0667, -0.0429, -0.6522, -0.0818,  0.4733,\n",
       "          -0.2070, -0.1998],\n",
       "         [-0.0594, -0.0986,  0.2173, -0.8324,  0.1346,  0.0480, -0.6569,  0.6211,\n",
       "          -0.5014, -0.2025],\n",
       "         [ 0.4021,  0.3105, -0.1062, -0.0585, -0.0949, -0.4025, -0.6088, -0.1245,\n",
       "          -0.2393,  0.5306]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.2725, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.3960, 0.0000],\n",
       "         [0.0642, 0.1404],\n",
       "         [0.0982, 0.0202],\n",
       "         [0.1800, 0.0000],\n",
       "         [0.1535, 0.0000],\n",
       "         [0.3419, 0.0000],\n",
       "         [0.0801, 0.0000],\n",
       "         [0.2396, 0.0546],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0141, 0.0000],\n",
       "         [0.2782, 0.0000],\n",
       "         [0.6096, 0.0000],\n",
       "         [0.0921, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0901, 0.0000],\n",
       "         [0.0000, 0.0808],\n",
       "         [0.5562, 0.0000],\n",
       "         [0.5363, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0425, 0.2489],\n",
       "         [0.3532, 0.0000],\n",
       "         [0.0512, 0.0000],\n",
       "         [0.3146, 0.0000],\n",
       "         [0.3440, 0.0000],\n",
       "         [0.0423, 0.0000],\n",
       "         [0.0511, 0.0439]], grad_fn=<ReluBackward0>))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2(train2_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_double_model(model,train_input,train_target,train_classes,nb_epochs=5):\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "    batch_size = 100\n",
    "    crit0 = nn.CrossEntropyLoss()\n",
    "    crit1 = nn.CrossEntropyLoss()\n",
    "    crit_comp = nn.CrossEntropyLoss()\n",
    "    for e in range(nb_epochs):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Progression:{:.2f}\".format(e/nb_epochs*100))\n",
    "        for inputs,comp_targs,classes in zip(train_input.split(batch_size),\n",
    "                                           train_target.split(batch_size),\n",
    "                                           train_classes.split(batch_size)):\n",
    "            targ0 = classes[:,0]\n",
    "            targ1 = classes[:,1]\n",
    "            x0,x1,comp = model(inputs)\n",
    "            loss0 = crit0(x0,targ0)\n",
    "            loss1 = crit1(x1,targ1)\n",
    "            loss_class = crit_comp(comp,comp_targs)\n",
    "            totloss = loss0 + loss1 + loss_class\n",
    "            model.zero_grad()\n",
    "            totloss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_double_model(model,train_input,train_target,train_classes):\n",
    "    assert(train_input.size(0) == train_target.size(0))\n",
    "    N = train_input.size(0)\n",
    "    tot_loss = 0\n",
    "    nb_correct = 0\n",
    "    batch_size = 20\n",
    "    \n",
    "    #given a prediction powre and the target, output the number of correctly classified samples\n",
    "    add_res = lambda pred,target:(torch.argmax(pred,axis = 1) == target).int().sum().item()\n",
    "    \n",
    "    score0 = 0\n",
    "    score1 = 0\n",
    "    scorecomp = 0\n",
    "    \n",
    "    for inputs,comp_targs,classes in zip(train_input.split(batch_size),\n",
    "                                           train_target.split(batch_size),\n",
    "                                        train_classes.split(batch_size)):\n",
    "        targ0 = classes[:,0]\n",
    "        targ1 = classes[:,1]\n",
    "        x0,x1,comp = model(inputs)\n",
    "        \n",
    "        score0 += add_res(x0,targ0)\n",
    "        score1 += add_res(x1,targ1)\n",
    "        \n",
    "        scorecomp += add_res\n",
    "        \n",
    "    acc0 = score0 / N\n",
    "    acc1 = score1 / N\n",
    "    acc_comp = scorecomp / N\n",
    "    \n",
    "    print(\"Accuracy first Network: %.2f\" % (acc0) )\n",
    "    print(\"Accuracy second Network: %.2f\" % (acc1))\n",
    "    print(\"Accuracy comparison: %.2f\" % (acc_comp))\n",
    "\n",
    "    return acc0,acc1,acc_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:80.00\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (20) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-bebe1dbc48f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_double_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain2_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain2_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain2_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy_double_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain2_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain2_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain2_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-866b3624b637>\u001b[0m in \u001b[0;36maccuracy_double_model\u001b[0;34m(model, train_input, train_target, train_classes)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscore0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0madd_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mscore1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0madd_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mscorecomp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcomp_targs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0macc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (20) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train_double_model(net2,train2_input,train2_target,train2_classes)\n",
    "accuracy_double_model(net2,train2_input,train2_target,train2_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/ymentha/anaconda3/envs/ML/lib/python3.7/site-packages/torch/tensor.py\u001b[0m(28)\u001b[0;36mwrapped\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     26 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 28 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-204-866b3624b637>\u001b[0m(24)\u001b[0;36maccuracy_double_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     22 \u001b[0;31m        \u001b[0mscore0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0madd_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m        \u001b[0mscore1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0madd_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 24 \u001b[0;31m        \u001b[0mscorecomp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcomp_targs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m    \u001b[0macc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  comp.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  comp_targs.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
